{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Detroit Police Department</h1>\n",
    "<p>For the final project we chose to analyze and visualize data of reported crimes in Detroit. The dataset is published at (https://data.detroitmi.gov), provided by Detroit Police Department. Python code written for the project can be found in the appendix of this notebook.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Motivation</h2>\n",
    "<p>Detroit, Michigan, is said to be the most dangerous city in the United States with a murder rate of 43,5 per 100.000 residents - almost ten times the average of the rest of the country.(http://www.forbes.com/sites/danielfisher/2015/10/29/americas-most-dangerous-cities-detroit-cant-shake-no-1-spot/#2c74325712c8)\n",
    "</p><p>\n",
    "One-third of the city is vacant, 60% of all children lives in poverty, and it takes the Detroit Police Department 58 minutes to respond to an emergency call and they only solves 10% of the reported crimes. Also, the City of Detroit went bankrupt back in 2013.\n",
    "(http://theeconomiccollapseblog.com/archives/25-facts-about-the-fall-of-detroit-that-will-leave-you-shaking-your-head)\n",
    "</p><p>\n",
    "The intention of this project is to to help the Detroit Police Department with an interactive predictive crime map of the most serious crimes and a tool to help them organize and manage patrolling units in scout car areas more efficiently. Crime mapping will be used to map and visualise predicted patterns and trends based on analysis of previous recorded criminal activities. A live view of hot spots can indicate the likeliness of where and when the next criminal activities will occur.\n",
    "</p><p>\n",
    "The acquired dataset of 244MB holds all reported crime incidents in Detroit from 2009 to present date, with 18 columns of information including GEO information, crime type, time, date, precinct, scout car area, etc. We will sort out the most serious crime types and focus on those, assuming that Detroit Police Department is more interested in focusing on for example homicides, drugs, and serious assaults compared to property damage and fraud. There are 1121494 rows, or reported crimes, from the 1st January 2009 - 12th April 2016, which is the date we started the preliminary data-analysis.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2. Basic Stats</h2>\n",
    "<p>Since the there are 46 different crime types in the original dataset, the main goal of the preliminary data analysis was to decide on what crimes to focus on. This was done in order to exclude irrelevant crimes to avoid their influence on crime prediction. Also, as can be seen in the following bar chart both “Miscellaneous” and “Other“ holds quite a lot of the reported crimes.</p>\n",
    "<p>This bar chart shows the amount of all crimes for the whole dataset.</p>\n",
    "![alt text](https://i.imgur.com/WBYYdIi.png)\n",
    "<p>These two bar chart shows the amount of all crimes to the left and focus crimes to the right.</p>\n",
    "![alt text](https://i.imgur.com/GbtRSfE.png)\n",
    "<p>This set of bar charts show the amount of each focus crime in each hour of the day. It’s interesting to see how each crime is distributed of a whole day. For example robberies mostly takes place at night when it’s dark, while burglaries takes place at broad daylight.</p>\n",
    "![alt text](https://i.imgur.com/3eZtASk.png)\n",
    "<p>This set of bar charts shows the yearly crime distribution for each focus crime (they started to spell kidnapping differently from 2016). Notice that the amount is this low in 2016 due because the data only goes till April 12th. Its interesting to see how both robberies and burglaries are decreasing, while assaults remains more constant.</p>\n",
    "![alt text](https://i.imgur.com/XxOq7NZ.png)\n",
    "<p>Here we see a kernel density estimation heatmap of aggravated assaults.</p>\n",
    "![alt text](http://i.imgur.com/O87viHw.png)\n",
    "<p>Here we see kernel density estimation heatmap of homicides.</p>\n",
    "![alt text](http://i.imgur.com/xHxGGby.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3. Theory</h2>\n",
    "<p>For the preliminary analysis we used kernel density estimation to create heatmaps for each of the focus crime in Detroit. The heatmaps were created from estimates of crime density, and visualizes how each criminal activity is distributed around the city.</p>\n",
    "<p>One of the main tools on the website is the predictive crime map, which is based on a k-nearest neighbours (knn) mode. The purpose of the predictive crime map is to predict the most likely crime at any geo location within Detroit boundries. The most natural choice of selecting a machine learning tool for that goal was k-nearest neghbours. KNN can classify a geo location according to the define number of nearest neighbours and this is exactly what is needed for this predictive crime map.</p>\n",
    "<p>As it comes to KNN, it is important to select a correct N - number of neighbours for the model. In order to find the best N number, the entire data of focus crimes has been valided for different N numbers. However, due to lack of time cross validation was not done but could potentially improve the model. In below figure, the results of validation for different N are shown. The error for each N has been calculated as the number of correct predictions diveded by the number of observations used to build the model.</p>\n",
    "\n",
    "![errgraph](http://i.imgur.com/QfFtEUU.png)\n",
    "\n",
    "<p>An intresting thing is that within the validaded range <0:15> the error continuosly grows and the best N according these classifiers results is just 1. The result is rather counter intuitive, before the validation was done, higher N had been expected to be the best.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>4. Visualizations</h2>\n",
    "<b>Predictive crime map</b>: Using knn to predict different crimes at a certain location in Detroit. The user can drag an drop an element on the map to pin-point where to do perform the calculations. In that way each police department in Detroit can see what crimes are more likely to happen at that time at specfic locations in the city.</p>\n",
    "\n",
    "<p><b>Chart 1: Animated Bubble Chart - Precincts in groups</b>: This animated bouble chart groups all SCAs in their given precincts in colors. Each SCA is represented as a bubble which size is determined by the given amount of crimes. This can be used to see what areas are more criminal and makes it easier for the different police departments to comapre their crime numbers with other precincts nearby.</p>\n",
    "\n",
    "<p><b>Chart 2: Bar Chart - Crimes in each SCA</b>: This simple bar chart shows the amount of reported focus crimes in each SCA, and can be used to get an overview of what crimes occurs the most.</p>\n",
    "\n",
    "<p><b>Chart 3: Bar Chart - Weekly numbers</b>: This bar chart shows the amount of reported focus crimes on each day of the week given a SCA and a crime. The user can input a certain SCA and a crime he wants to investigate, and then see at what particular days that crime occurs the most.</p>\n",
    "\n",
    "<p><b>Chart 4: Bar Chart: Daily overview</b>: Shows the amount of reported focus crimes, over 24 hours, given a SCA and a crime. This comes in handy for the police when wanting to improve how they organize their patroling units around the city of Detroit.</p>\n",
    "\n",
    "<p><b>Chart 5: Scatter plot - Weekly overview</b>: Given a SCA and a crime, the chart shows the day and the time when the crime has occured. The radius of the circle represents the crime count. In that way, the user can see when each crime usually occurs both at what day(s) and what time(s) of the day.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>5. Discussion</h2>\n",
    "<p>We made a decent website for Detroit Police Department, which can be used for several different purposes. All the visualizations works as intended although there still are some additional functionalities which would have added to overall usefulness of the website.</p>\n",
    "\n",
    "<p>Considering the different ways of visualizing the open data we analyzed, some of the charts will be more usefull to the police than others. For example the bar chart of amount of crimes in each SCA does not realy provide the police with useful insights which they can use in their daily routines. However, the predictive crime map, the bubble charts, and the a few of the bar charts can all be used as tools for improving the management of patroling units around the city.</p>\n",
    "\n",
    "<p>The intention with the website was to make the police work smarter by letting them organize their patroling units based on actual data. However, the charts we provide still demands manual interaction. An improvement could be to provide the user with suggestions of where to move the patroling units, although this would require data of where the units are patroling at present time. These data are not available to us.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Appendix A. Python Code</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>READ PREPARE DATA SET</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from django.core.files import File\n",
    "from collections import defaultdict\n",
    "from os import path\n",
    "\n",
    "csvFilePath = \"app/static/app/datasets/Detroit_Focus_Crimes_12April_2016.csv\"\n",
    "\n",
    "# Set of focus crimes\n",
    "focuscrimes_cetegories = set(['AGGRAVATED ASSAULT','ROBBERY','BURGLARY','HOMICIDE','WEAPONS OFFENSES',\n",
    "                    'KIDNAPPING','ARSON','ASSAULT','DANGEROUS DRUGS','ARSON'])\n",
    "\n",
    "# Key is a focus crime, value is a list of locations corresponding to the focus crime\n",
    "geo_data_by_focuscrime = defaultdict(lambda : {\"lat\" : [], \"lon\" : []})\n",
    "\n",
    "def get_data():\n",
    "    global geo_data_by_focuscrime\n",
    "    dataSet = []\n",
    "\n",
    "    # Read csv file and populate locations_by_focuscrime dic\n",
    "    with open(csvFilePath) as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            crime = row['CATEGORY']\n",
    "            \n",
    "            # Skip row if values cannot be parsed\n",
    "            try :\n",
    "                x = float(row['LON'])\n",
    "                y = float(row['LAT'])\n",
    "                hour = int(row['HOUR'])\n",
    "            except :\n",
    "                continue\n",
    "       \n",
    "            #Filter due to an oulier in the latitude:\n",
    "            if (y > 45 or y < 40) : continue\n",
    "            if (x > -80 or x < -85) : continue\n",
    "            if (crime not in focuscrimes_cetegories) : continue\n",
    "            if (hour < 0 or hour > 24) : continue\n",
    "            \n",
    "            dataSet.append(row)\n",
    "            \n",
    "            if crime in focuscrimes_cetegories:\n",
    "                geo_data_by_focuscrime[crime][\"lon\"].append(x)\n",
    "                geo_data_by_focuscrime[crime][\"lat\"].append(y)\n",
    "\n",
    "    return dataSet\n",
    "\n",
    "focuscrimes_data = get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>PLOT KERNEL DENSITY ESTIMATION FOR EACH FOCUS CRIME</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import geoplotlib\n",
    "from geoplotlib.utils import BoundingBox, DataAccessObject\n",
    "\n",
    "# Plot kernel density estimation of all incidents for each of the focus crimes\n",
    "for category, geo_data in geo_data_by_focuscrime.iteritems():\n",
    "    # Print category name\n",
    "    print \"Kerne density estimation for crime category: \" + category\n",
    "    \n",
    "    # Visualize kernel density estimation of the given crime\n",
    "    geoplotlib.kde(geo_data, bw=4, cut_below=1e-4)\n",
    "    \n",
    "    # Prepare data for bounding box\n",
    "    max_lat = max(geo_data['lat'])\n",
    "    min_lon = min(geo_data['lon'])\n",
    "    min_lat = min(geo_data['lat'])\n",
    "    max_lon = max(geo_data['lon'])\n",
    "    \n",
    "    # Create and set bounding box for map of San Francisko\n",
    "    bbox = BoundingBox(north=max_lat, west=min_lon, south=min_lat, east=max_lon)\n",
    "    geoplotlib.set_bbox(bbox)\n",
    "\n",
    "    # Plot inline\n",
    "    geoplotlib.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>K-NEAREST NEIGHBOURS FUNCTIONS</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "# Create X array with samples and Y array with targets\n",
    "for category, geo_data in geo_data_by_focuscrime.iteritems():\n",
    "    X.extend(zip(geo_data['lat'], geo_data['lon']))\n",
    "    Y.extend(category for _ in range(0, len(geo_data['lon'])))\n",
    "    \n",
    "def classify(lat,lon,knn_classifier):\n",
    "    return knn_classifier.predict([[lat,lon]])[0]\n",
    "\n",
    "def classify(geo,knn_classifier):\n",
    "    return knn_classifier.predict([geo])[0]\n",
    "\n",
    "def initClassifier(geo_data_by_focuscrime, n):\n",
    "\n",
    "    # Create neighbours classirier for n neighbors and fit the data\n",
    "    knn_class=neighbors.KNeighborsClassifier(n)\n",
    "    knn_class.fit(X, Y)\n",
    "    knn_classifier = knn_class\n",
    "\n",
    "    return knn_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>FINDING BEST N FOR K-NEAREST NEIGHBOURS</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from __future__ import division\n",
    "\n",
    "n_neighbors = range(100,101)\n",
    "all_predictions = []\n",
    "all_errs = []\n",
    "\n",
    "# Init knn classifier for each n and calculate predictions and prediction errors for all points from data sets\n",
    "for n in n_neighbors :\n",
    "    \n",
    "    # Init classifier for n\n",
    "    classifier = initClassifier(geo_data_by_focuscrime, n)\n",
    "    \n",
    "    # Classify/predict data\n",
    "    predictions = classifier.predict(X)\n",
    "    all_predictions.append(predictions)\n",
    "    \n",
    "    # Calculate diffarance between the actual data and the predicted data\n",
    "    # diff list will contain true if they are equal else false\n",
    "    diff = numpy.array(Y) == numpy.array(predictions)\n",
    "    \n",
    "    # Error equal to the number of uncorrectly predicted data diveded by the number of data rows \n",
    "    err = diff.tolist().count(0) / len(Y) * 100\n",
    "    all_errs.append(err)\n",
    "    \n",
    "\n",
    "# PLOT GRAPH\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.ylim([0,max(all_errs)])\n",
    "plt.xlim([0,max(n_neighbors) + 1])\n",
    "plt.title('Error rate vs. # of N')\n",
    "plt.xlabel('# of N')\n",
    "plt.ylabel('Error rate (%)')\n",
    "plt.plot(n_neighbors, all_errs, color='r')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
